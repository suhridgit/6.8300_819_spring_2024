{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPyxgwfCtkBH"
   },
   "source": [
    "Part of the code is based on the Madry Lab's robustness toolkit and Google DeepDream. You can check out more here https://github.com/MadryLab\n",
    "and here https://distill.pub/2017/feature-visualization/\n",
    "\n",
    "\n",
    "**Note:** To speed up the execution of the experiments, we recommend using GPU acceleration. If you are running the notebook on Colab, select GPU as your runtime type as follows: Runtime → Change runtime type → Hardware accelerator → GPU → Save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# staring pset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQpJ32lb6MmD"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlg48zONYlLy"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def download(url, fn=None):\n",
    "  if fn is None:\n",
    "    fn = url.split('/')[-1]\n",
    "  r = requests.get(url)\n",
    "  if r.status_code == 200:\n",
    "      open(fn, 'wb').write(r.content)\n",
    "      print(\"{} downloaded: {:.2f} KB\".format(fn, len(r.content)/1024.))\n",
    "  else:\n",
    "      print(\"url not found:\", url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7p15MZAUU7c"
   },
   "source": [
    "Download the test image and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zK12DvgLzrz"
   },
   "outputs": [],
   "source": [
    "download('http://6.869.csail.mit.edu/fa19/psets19/pset6/imagenet_classes.txt')\n",
    "download('http://6.869.csail.mit.edu/fa19/psets19/pset6/WelshCorgi.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSWy3KeHY7Vj"
   },
   "source": [
    "\n",
    "\n",
    "# Neural Network Inference (Problem 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_hXG7PpZItx"
   },
   "source": [
    "In this exercise, you will be playing with a convolutional neural network to classify images into semantic labels. You will be working with ResNet50, a variant of the residual convolutional network architecture. We will be testing the network to classify an image into one of the 1000 ImageNet categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt5j4rILakPs"
   },
   "source": [
    "### Load ImageNet class names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8S1KHKKaurC"
   },
   "outputs": [],
   "source": [
    "with open('imagenet_classes.txt', 'r') as f:\n",
    "  imagenet_classes = f.readlines()\n",
    "  imagenet_classes_short = [x.strip().split(',')[-1] for x in imagenet_classes]\n",
    "\n",
    "print('Imagenet classes')\n",
    "for it, class_name in enumerate(imagenet_classes):\n",
    "  if it == 3:\n",
    "    print('...')\n",
    "  elif it < 4 or it > 997:\n",
    "    print('{}. {}'.format(it, class_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf0tJQ3kZzkx"
   },
   "source": [
    "## Running a randomly initialized network\n",
    "We will start by using a randomly initalized ResNet50 to perform classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3OppKjUbhMw"
   },
   "source": [
    "### Load a randomly initalized network (Problem 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDy2nbxgdLpx"
   },
   "outputs": [],
   "source": [
    "# Download ResNet50 from Pytorch repository\n",
    "arch = 'resnet50'\n",
    "model = models.__dict__[arch]()\n",
    "# We set it in eval, so that batch normalization layers are not updated\n",
    "model.eval();\n",
    "if cuda_available:\n",
    "  model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqSZRVUJVjAb"
   },
   "outputs": [],
   "source": [
    "# Visualize the last layer\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DskLmy8cINu"
   },
   "source": [
    "### Preparing the image for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "635O0bKbb2km"
   },
   "outputs": [],
   "source": [
    "# Load the image we will be playing with\n",
    "img = cv2.imread('WelshCorgi.jpeg')\n",
    "plt.imshow(img[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPvNDdZh6Q56"
   },
   "outputs": [],
   "source": [
    "# In order to run the image through a model, we need to prepare it first.\n",
    "# This includes:\n",
    "# 1. Resizing the image to an appropiate size for the network.\n",
    "# 2. Converting the image to a tensor - this will normalize the image in the\n",
    "#    0-1 range and change the channel order.\n",
    "# 3. Normalizing the image.\n",
    "# 4. Puting the image in a batch. In our case, we will use a single element\n",
    "#    batch.\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def prepare_image(image_cv2, do_normalize=True):\n",
    "  # Resize\n",
    "  img = cv2.resize(image_cv2, (224, 224))\n",
    "  img = img[:, :, ::-1].copy()\n",
    "  # Convert to tensor\n",
    "  tensor_img = transforms.functional.to_tensor(img)\n",
    "\n",
    "  # Possibly normalize\n",
    "  if do_normalize:\n",
    "    tensor_img = normalize(tensor_img)\n",
    "  # Put image in a batch\n",
    "  batch_tensor_img = torch.unsqueeze(tensor_img, 0)\n",
    "\n",
    "  # Put the image on the GPU\n",
    "  if cuda_available:\n",
    "    batch_tensor_img = batch_tensor_img.cuda()\n",
    "  return batch_tensor_img\n",
    "\n",
    "\n",
    "def UnNormalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]):\n",
    "  std_arr = torch.tensor(std)[:, None, None]\n",
    "  mean_arr = torch.tensor(mean)[:, None, None]\n",
    "  def func(img):\n",
    "    img = img.clone()\n",
    "    img *= std_arr\n",
    "    img += mean_arr\n",
    "    return img\n",
    "  return func\n",
    "unnormalize = UnNormalize()\n",
    "\n",
    "def obtain_image(tensor_img, do_normalize=True):\n",
    "  tensor_img = tensor_img.cpu()\n",
    "  if do_normalize:\n",
    "    tensor_img = unnormalize(tensor_img)\n",
    "  img = transforms.functional.to_pil_image((tensor_img.data))\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRYoMgRZdR6f"
   },
   "source": [
    "### Classifying the image (Problem 2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2GdV2Vyek9V"
   },
   "source": [
    "This architecture outputs a vector of 1000 elements, that correspond to the class logits: each of the class probabilities before doing a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzANMajcdHje"
   },
   "outputs": [],
   "source": [
    "# Prepare the image\n",
    "batch_normalized_img = prepare_image(img)\n",
    "# Run it through the network\n",
    "output = model(batch_normalized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWB5WZM8e7Ty"
   },
   "source": [
    "Let's visualize the top classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sErC9LuC7mEt"
   },
   "outputs": [],
   "source": [
    "def plot_top_classes(values, top_k=5):\n",
    "  sorted_classes = np.argsort(-values)\n",
    "  class_ids = sorted_classes[:top_k]\n",
    "  class_names = [imagenet_classes_short[it] for it in list(class_ids)]\n",
    "  class_values = values[class_ids]\n",
    "  plt.bar(class_names, class_values)\n",
    "  plt.xticks(rotation=60)\n",
    "\n",
    "\n",
    "plot_top_classes(output[0,:].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0effvkXepHnM"
   },
   "source": [
    "### Load and run a pre-trained network (Problem 2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eOrQ4Hhfyc4"
   },
   "source": [
    "Unsurprisingly, the network predictions above have nothing to do with the image, since the network was intialized from scratch. Instead, we will initialize the network with pre-trained weights (from a neural network that has been trained on the ImageNet dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYLm9NKRgWNp"
   },
   "outputs": [],
   "source": [
    "arch = 'resnet50'\n",
    "model = models.__dict__[arch](pretrained=True)\n",
    "model.eval();\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sni0vPs2MCp0"
   },
   "outputs": [],
   "source": [
    "output = model(batch_normalized_img.cuda())\n",
    "plot_top_classes(output[0,:].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxuPDY7Zgvgr"
   },
   "source": [
    "The top predictions seem to make much more sense now. But it is not clear how to interpret the logits (the raw output scalars). Please normalize the logits into the probability range using the `torch.nn.functional.softmax` function (TODO1).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KetuX0vmPayI"
   },
   "outputs": [],
   "source": [
    "def output2prob(output):\n",
    "  ### TODO1\n",
    "  # Your code here:\n",
    "  prob =\n",
    "  ###\n",
    "  return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dCUjauDtKZ7"
   },
   "source": [
    "\n",
    "\n",
    "Now rerun the network, passing the output through our `output2prob` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WktEvr48hbrm"
   },
   "outputs": [],
   "source": [
    "output = model(batch_normalized_img.cuda())\n",
    "prob = output2prob(output)\n",
    "plot_top_classes(prob[0,:].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIxm5IhVdN_e"
   },
   "source": [
    "# Adversarial Examples (Problem 4)\n",
    "\n",
    "Although the above results show that deep neural networks can classify the image correctly as *corgi*, it is actually not robust! In this section, we are going to show that neural networks can be \"fooled\" when some unperceivable noises are added to the image.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/4000/1*PmCgcjO3sr3CPPaCpy5Fgw.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Note that the left and right images look the same to the human eyes, but result in very different neural network predictions. Since the right image can pose security threats to our model, we call these images **adversarial examples**.\n",
    "\n",
    "How can we create adversarial examples? Remember that when training a neural network, we use backpropagation to obtain the gradient of the loss with respect to the network parameters, and use it to update the the parameters that minimize the loss.\n",
    "\n",
    "We can also use backpropagation to obtain the gradient of the loss with respect to the input image, given the network parameters. If we update the image according to that gradient, we can generate images that maximize certain activations, or minimize the loss. If properly applied, small changes in an image can completely change the neural network's prediction and result in adversarial examples.\n",
    "\n",
    "\n",
    "\n",
    "Let's try to fool the neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-qcMwfDVgPC"
   },
   "source": [
    "## Attack 1 (Problem 4a)\n",
    "We will use the following function to generate the adversarial examples. This function will take as input 1) the neural network model and 2) the normal image and output an adversarial example, a modified image that looks similar to the normal image but fools the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdfeLpFmTvwq"
   },
   "outputs": [],
   "source": [
    "def generate_adversarial_example(model_fn, x, class_id, n_iter=200):\n",
    "  \"\"\"\n",
    "  :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "  :param x: input tensor.\n",
    "  :param class_id: the id of the target class.\n",
    "  :return: a tensor for the adversarial example\n",
    "  \"\"\"\n",
    "  for i in tqdm(range(n_iter)):\n",
    "    ### TODO2\n",
    "    # You should:\n",
    "    # 1. Run input image/tensor x through the model to obtain the raw, unnormalized logits.\n",
    "    # 2. Define a loss or objective that maximizes the log probability of the target class.\n",
    "    # (Note - You can consider using off-the-shelf loss functions in torch that directly take\n",
    "    #  logits as input OR define your own function to compute log probabilities from logits)\n",
    "    # 3. Compute the gradient of the objective with respect to x using\n",
    "    #    torch.autograd.grad\n",
    "    #\n",
    "    # Your code here:\n",
    "    logit =\n",
    "    loss =\n",
    "    gradient, =\n",
    "    ###\n",
    "    x = step.step(x, -1*gradient)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-tUmye5T2-0"
   },
   "source": [
    "### Step class\n",
    "We will use the following class to generate our image. This class will take a tensor x corresponding to the image a g corresponding to the gradient and will update x according to g. To ensure that the updated image lies in a reasonable manifold, we will also allow for a projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JvM_cZJvrfm"
   },
   "outputs": [],
   "source": [
    "class StepImage():\n",
    "  def __init__(self, orig_input, step_size=2, is_normalized=True,\n",
    "               renorm=True, eps=30, norm_update='l2'):\n",
    "    self.orig_input = orig_input\n",
    "    if is_normalized:\n",
    "      mean=[0.485, 0.456, 0.406]\n",
    "      std= [0.229, 0.224, 0.225]\n",
    "    else:\n",
    "      mean=[0., 0., 0.]\n",
    "      std= [1., 1., 1.]\n",
    "\n",
    "    is_cuda = orig_input.is_cuda\n",
    "    self.mean = torch.tensor(mean)[:, None, None]\n",
    "    self.std = torch.tensor(std)[:, None, None]\n",
    "    if is_cuda:\n",
    "      self.mean = self.mean.cuda()\n",
    "      self.std = self.std.cuda()\n",
    "    self.eps = eps\n",
    "    self.renorm = renorm\n",
    "    self.step_size = step_size\n",
    "    self.norm_update = norm_update\n",
    "\n",
    "  def project(self, x):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    diff = x - self.orig_input\n",
    "    if self.renorm:\n",
    "      diff = diff.renorm(p=2, dim=0, maxnorm=self.eps)\n",
    "    val_projected = self.orig_input + diff\n",
    "\n",
    "    val_projected *= self.std\n",
    "    val_projected += self.mean\n",
    "    val_clamped = torch.clamp(val_projected, 0, 1)\n",
    "    val_clamped -= self.mean\n",
    "    val_clamped /= self.std\n",
    "    return val_clamped\n",
    "\n",
    "  def step(self, x, g):\n",
    "    step_size = self.step_size\n",
    "    # Scale g so that each element of the batch is at least norm 1\n",
    "    if self.norm_update == 'l2':\n",
    "      l = len(x.shape) - 1\n",
    "      g_norm = torch.norm(g.view(g.shape[0], -1), dim=1).view(-1, *([1]*l))\n",
    "    else:\n",
    "      g_norm = torch.torch.abs(g).mean()\n",
    "    scaled_g = g / (g_norm + 1e-10)\n",
    "    stepped = x + scaled_g * step_size\n",
    "    projected = self.project(stepped)\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jiLAg_cwedQ"
   },
   "source": [
    "### Attack 1\n",
    "\n",
    "We will now update the image to make the model think this image is a **Tarantula (id 76)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVcd6T4kNPTZ"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('WelshCorgi.jpeg')\n",
    "starting_image = prepare_image(img)\n",
    "\n",
    "# This allows to backpropagate the image\n",
    "batch_tensor = starting_image.clone().requires_grad_(True)\n",
    "\n",
    "# This updates the image according to some gradient\n",
    "step = StepImage(starting_image, step_size=3, renorm=True)\n",
    "batch_tensor = generate_adversarial_example(model, batch_tensor, 76)\n",
    "print(torch.norm(batch_tensor - starting_image, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5Q9fhmhc2QP"
   },
   "source": [
    "### Visualize the original and attacked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otaK0LBxy_Nc"
   },
   "outputs": [],
   "source": [
    "original_image = obtain_image(starting_image[0, :], do_normalize=True)\n",
    "attacked_image_tarantula = obtain_image(batch_tensor[0, :], do_normalize=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].set_title('Original image')\n",
    "axs[0].imshow(original_image)\n",
    "axs[1].set_title('Attacked image')\n",
    "axs[1].imshow(attacked_image_tarantula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EPBTz506fDF"
   },
   "source": [
    "### Compute the updated probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHfl7w156bkt"
   },
   "outputs": [],
   "source": [
    "output = model(batch_tensor)\n",
    "prob = output2prob(output)\n",
    "plot_top_classes(prob[0,:].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qj6D7UfbGjW"
   },
   "source": [
    "## Attack 2 (Problem 4b)\n",
    "\n",
    "We will now update the image to make the model think this image is a **Tiger Cat (id 282)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhiwPiMabF6Z"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "starting_image = prepare_image(img)\n",
    "batch_tensor = starting_image.clone()\n",
    "batch_tensor.requires_grad_(True)\n",
    "step = StepImage(starting_image, step_size=3, renorm=True)\n",
    "batch_tensor = generate_adversarial_example(model, batch_tensor, 282)\n",
    "print(torch.norm(batch_tensor - starting_image, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVCTDYe_bYBf"
   },
   "source": [
    "### Visualize the original and attacked images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7JPgYZzdDoO"
   },
   "outputs": [],
   "source": [
    "original_image = obtain_image(starting_image[0, :], do_normalize=True)\n",
    "attacked_image_siamese = obtain_image(batch_tensor[0, :], do_normalize=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].set_title('Original image')\n",
    "axs[0].imshow(original_image)\n",
    "axs[1].set_title('Attacked image')\n",
    "axs[1].imshow(attacked_image_siamese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY4C-CjGdBJm"
   },
   "source": [
    "### Compute the updated probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJsHpWKPbMSK"
   },
   "outputs": [],
   "source": [
    "output = model(batch_tensor)\n",
    "prob = output2prob(output)\n",
    "plot_top_classes(prob[0,:].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0JKc0QEdcCt"
   },
   "source": [
    "## Comparing Images (Problem 4c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0sBnS-xdcPq"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].set_title('Original image')\n",
    "axs[0].imshow(original_image)\n",
    "axs[1].set_title('Attacked image 1')\n",
    "axs[1].imshow(attacked_image_tarantula)\n",
    "axs[2].set_title('Attacked image 2')\n",
    "axs[2].imshow(attacked_image_siamese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raUVsO9k6_lV"
   },
   "source": [
    "## Maximizing layers (Problem 4d) [6.8300 only]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8dBzJADpCV2"
   },
   "outputs": [],
   "source": [
    "# This function creates a function that gives the output of a given\n",
    "# network at layer: layer_id.\n",
    "# Usage:\n",
    "# model_l = model_layer(model, layer_id_interest)\n",
    "# output_layer_interest = model_l(input)\n",
    "def model_layer(model, layer_id):\n",
    "  layers = [model.layer1, model.layer2, model.layer3, model.layer4]\n",
    "  def forward(input):\n",
    "    layers_used = layers[:(layer_id+1)]\n",
    "    x = input\n",
    "    x = model.conv1(x)\n",
    "    x = model.bn1(x)\n",
    "    x = model.relu(x)\n",
    "    x = model.maxpool(x)\n",
    "    for l in layers_used:\n",
    "      x = l(x)\n",
    "    return x\n",
    "  return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxMnljtC7YaE"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "starting_image = torch.rand((1, 3, 224, 224))\n",
    "if cuda_available: starting_image = starting_image.cuda()\n",
    "batch_tensor = starting_image.clone().requires_grad_(True)\n",
    "step = StepImage(starting_image, step_size=0.05, renorm=False, norm_update='abs', is_normalized=False)\n",
    "\n",
    "### TODO3\n",
    "# Modify Layer ID (0-3) to select feature from different layers\n",
    "layer_id =\n",
    "###\n",
    "model_l = model_layer(model, layer_id)\n",
    "\n",
    "# target image and the embedding\n",
    "target_image = prepare_image(img)\n",
    "target_feat = model_l(target_image)\n",
    "\n",
    "for _ in tqdm(range(200)):\n",
    "  feat = model_l(batch_tensor)\n",
    "  ### TODO4\n",
    "  # You should minimize the L2 norm between feat and target_feat\n",
    "  # Your code here:\n",
    "  loss =\n",
    "  ###\n",
    "  gradient, = torch.autograd.grad(loss, batch_tensor)\n",
    "  batch_tensor = step.step(batch_tensor, -gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8QL9gZZ8GGr"
   },
   "outputs": [],
   "source": [
    "original_image = obtain_image(starting_image[0, :], do_normalize=False)\n",
    "modified_image = obtain_image(batch_tensor[0, :], do_normalize=False)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].set_title('Original random image')\n",
    "axs[0].imshow(original_image)\n",
    "axs[1].set_title('Modified image')\n",
    "axs[1].imshow(modified_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSSfWN3NGUot"
   },
   "source": [
    "## Robust model (Problem 4e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24BA6cCIqZWG"
   },
   "source": [
    "The property shown above is clearly not desirable. Creating such adversaries would allow to fool networks without humans noticing it, which could cause security issues. To address this, some researchers have proposed methods \\[1\\] for training robust models! Let's see what will happen if we attack the robust models:\n",
    "\n",
    "\\[1\\] [Image Synthesis with a Single (Robust) Classifier](https://arxiv.org/pdf/1906.09453.pdf), Santurkar et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgUEP0ojr0t7"
   },
   "source": [
    "### Download the robustly trained model and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-I9Z3T3lXa-7"
   },
   "outputs": [],
   "source": [
    "download('http://6.869.csail.mit.edu/fa19/psets19/pset6/imagenet_l2_3_0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0OgFQwfgEus"
   },
   "outputs": [],
   "source": [
    "if cuda_available:\n",
    "  model_weights = torch.load('imagenet_l2_3_0.pt')\n",
    "else:\n",
    "  model_weights = torch.load('imagenet_l2_3_0.pt', map_location=torch.device('cpu'))\n",
    "model_weights_modified = {name.split('model.')[1]: value for name, value in model_weights['model'].items() if 'model' in name}\n",
    "model.load_state_dict(model_weights_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL7_voVjsQ1Z"
   },
   "source": [
    "Here we show that the input image is modified when maximizing the class **Tiger Cat** (id 282)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iy6YWnmeGkOH"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "initial_image = prepare_image(img, do_normalize=False)\n",
    "batch_tensor = initial_image.clone()\n",
    "batch_tensor.requires_grad_(True)\n",
    "step = StepImage(initial_image, step_size=2, renorm=True, is_normalized=False, eps=30)\n",
    "batch_tensor = generate_adversarial_example(model, batch_tensor, 282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWm3NgrhHBPm"
   },
   "outputs": [],
   "source": [
    "image = obtain_image(initial_image[0, :], do_normalize=False)\n",
    "plt.imshow(image)\n",
    "plt.figure()\n",
    "image = obtain_image(batch_tensor[0, :], do_normalize=False)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl_K-LTms7i0"
   },
   "source": [
    "### Compute the updated log-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAHsAv8Qs7Gv"
   },
   "outputs": [],
   "source": [
    "output = model(batch_tensor)\n",
    "prob = output2prob(output)\n",
    "plot_top_classes(prob[0,:].cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CqBKJpqdlqg"
   },
   "source": [
    "## Repeat Problem 4d using the robust model (Problem 4f)\n",
    "\n",
    "The robust model can also change the resulting image when trying to infer the input from the embedding. Repeat all the procedure in question 4.d with the robust model. Does the result look different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaNQ-6vQf-Qf"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "starting_image = torch.rand((1, 3, 224, 224))\n",
    "if cuda_available: starting_image = starting_image.cuda()\n",
    "batch_tensor = starting_image.clone().requires_grad_(True)\n",
    "step = StepImage(starting_image, step_size=0.05, renorm=False, norm_update='abs', is_normalized=False)\n",
    "\n",
    "\n",
    "### TODO5\n",
    "# Modify Layer ID (0-3) to select feature from different layers\n",
    "layer_id =\n",
    "###\n",
    "model_l = model_layer(model, layer_id)\n",
    "\n",
    "# target image\n",
    "target_image = prepare_image(img)\n",
    "target_feat = model_l(target_image)\n",
    "\n",
    "for _ in tqdm(range(200)):\n",
    "  feat = model_l(batch_tensor)\n",
    "  ### TODO6\n",
    "  # You should minimize the L2 norm between feat and target_feat\n",
    "  # Your code here:\n",
    "  loss =\n",
    "  ###\n",
    "  gradient, = torch.autograd.grad(loss, batch_tensor)\n",
    "  batch_tensor = step.step(batch_tensor, -gradient)\n",
    "\n",
    "original_image = obtain_image(starting_image[0, :], do_normalize=False)\n",
    "modified_image = obtain_image(batch_tensor[0, :], do_normalize=False)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].set_title('Original random image')\n",
    "axs[0].imshow(original_image)\n",
    "axs[1].set_title('Modified image')\n",
    "axs[1].imshow(modified_image)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
